import chromadb
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sentence_transformers import SentenceTransformer  # Use proper embeddings

# âœ… Initialize ChromaDB client
chroma_client = chromadb.PersistentClient(path="./chroma_db")

# âœ… Get available collections
collections = chroma_client.list_collections()
if not collections:
    print("âš ï¸ No collections found in ChromaDB. Please ensure data is added first.")
    exit()

# âœ… Fix for Chroma v0.6.0+ (Use only the collection name string)
collection_name = collections[0]
print(f"ğŸ”¹ Using collection: {collection_name}")

# âœ… Load the collection
collection = chroma_client.get_collection(collection_name)

# âœ… Fetch all stored embeddings
results = collection.get(include=["embeddings", "metadatas"])

# âœ… Fix: Properly check if embeddings exist
if results["embeddings"] is None or len(results["embeddings"]) == 0:
    print("âš ï¸ No embeddings found in the collection.")
    exit()

embeddings = np.array(results["embeddings"])
metadata = results["metadatas"]

# âœ… Fix: Normalize stored embeddings
embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)

# âœ… Use a proper embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")  # Load a model

# âœ… Display embeddings while typing a query
while True:
    query = input("ğŸ” Enter your query (or type 'exit' to quit): ")
    if query.lower() == "exit":
        break

    # âœ… Encode query properly
    query_embedding = model.encode(query, normalize_embeddings=True)

    # âœ… Compute similarity (cosine similarity)
    similarities = np.dot(embeddings, query_embedding)

    # âœ… Get top result
    top_index = np.argmax(similarities)
    print(f"ğŸ”¹ Closest match: {metadata[top_index]} (Similarity: {similarities[top_index]:.2f})")

# âœ… Model Evaluation Metrics

# ğŸ¯ Dummy ground truth labels and predictions (Replace with actual labels)
y_true = np.random.randint(0, 2, len(embeddings))  # Actual labels (0 or 1)
y_pred = np.random.randint(0, 2, len(embeddings))  # Predicted labels

# ğŸ“Š Accuracy Score
accuracy = accuracy_score(y_true, y_pred)
print(f"\nâœ… Model Accuracy: {accuracy:.2f}")

# ğŸ“Š Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print("\nConfusion Matrix:\n", cm)

# ğŸ“Š Classification Report
print("\nClassification Report:\n", classification_report(y_true, y_pred))

# ğŸ“Š Plot Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
